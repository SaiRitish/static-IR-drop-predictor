# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZDUra3Qw6YZgpFbbsYs4NOSLKLv1TaAj
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import (
    Input,
    Conv2D,
    MaxPooling2D,
    UpSampling2D,
    Concatenate,
    BatchNormalization,
    Dropout,
    Add,
)
from tensorflow.keras.models import Model
from tensorflow.keras.applications import VGG19


# Debugging helper
def debug(message):
    print(f"[DEBUG] {message}")


# --- Preprocessing ---
base_path = "/content/drive/My Drive/ML-for-IR-drop-main/benchmarks/fake-circuit-data/"

# Dynamically find files
available_current_files = [
    os.path.join(base_path, file)
    for file in os.listdir(base_path)
    if "_current" in file and file.endswith(".csv") and "current_map" in file
]
available_pdn_files = [
    os.path.join(base_path, file)
    for file in os.listdir(base_path)
    if "pdn_density" in file and file.endswith(".csv")
]
available_dist_files = [
    os.path.join(base_path, file)
    for file in os.listdir(base_path)
    if "eff_dist" in file and file.endswith(".csv")
]
available_ir_drop_files = [
    os.path.join(base_path, file)
    for file in os.listdir(base_path)
    if "ir_drop" in file and file.endswith(".csv") and "current_map" in file
]


# Sort by numeric indices
def extract_index(file_name):
    return int(file_name.split("map")[1].split("_")[0])


available_current_files.sort(key=lambda f: extract_index(f))
available_pdn_files.sort(key=lambda f: extract_index(f))
available_dist_files.sort(key=lambda f: extract_index(f))
available_ir_drop_files.sort(key=lambda f: extract_index(f))

# Ensure alignment of files
if not (
    len(available_current_files)
    == len(available_pdn_files)
    == len(available_dist_files)
    == len(available_ir_drop_files)
):
    raise ValueError(
        f"Mismatch in file counts: {len(available_current_files)} currents, {len(available_pdn_files)} PDNs, {len(available_dist_files)} distances, {len(available_ir_drop_files)} IR drops."
    )

debug(
    f"Found {len(available_current_files)} current, {len(available_pdn_files)} PDN density, {len(available_dist_files)} effective distance, and {len(available_ir_drop_files)} IR drop files."
)


# Preprocess CSV files
def preprocess_csv(file_path, target_shape=(128, 128)):
    debug(f"Processing file: {file_path}")
    data = pd.read_csv(file_path, header=None).to_numpy(dtype=np.float32)
    data = tf.image.resize(data[..., np.newaxis], target_shape, method="bilinear").numpy()
    max_val = np.max(data)
    return data / max_val if max_val > 0 else data


# Load and preprocess data
input_currents = np.array([preprocess_csv(file) for file in available_current_files])
input_pdns = np.array([preprocess_csv(file) for file in available_pdn_files])
input_dists = np.array([preprocess_csv(file) for file in available_dist_files])
output_images = np.array([preprocess_csv(file) for file in available_ir_drop_files])

# --- Data Splitting ---
debug("Splitting data...")
split_idx = len(input_currents) - 10  # Train on all but the last 10
train_currents, test_currents = input_currents[:split_idx], input_currents[split_idx:]
train_pdns, test_pdns = input_pdns[:split_idx], input_pdns[split_idx:]
train_dists, test_dists = input_dists[:split_idx], input_dists[split_idx:]
train_outputs, test_outputs = output_images[:split_idx], output_images[split_idx:]

debug(f"Training size: {len(train_currents)}, Testing size: {len(test_currents)}")

# --- Loss Functions ---
def dice_loss(y_true, y_pred):
    numerator = 2 * tf.reduce_sum(y_true * y_pred)
    denominator = tf.reduce_sum(y_true + y_pred)
    return 1 - numerator / (denominator + tf.keras.backend.epsilon())


def mape_loss(y_true, y_pred):
    return tf.reduce_mean(
        tf.abs((y_true - y_pred) / tf.clip_by_value(y_true, 1e-7, tf.reduce_max(y_true)))
    )


# Load VGG19 for perceptual loss
vgg = VGG19(weights="imagenet", include_top=False, input_shape=(128, 128, 3))
vgg.trainable = False
perceptual_layer = vgg.get_layer("block5_conv4").output
perceptual_model = Model(inputs=vgg.input, outputs=perceptual_layer)


def perceptual_loss(y_true, y_pred):
    y_true_rgb = tf.image.grayscale_to_rgb(y_true)
    y_pred_rgb = tf.image.grayscale_to_rgb(y_pred)
    true_features = perceptual_model(y_true_rgb)
    pred_features = perceptual_model(y_pred_rgb)
    return tf.reduce_mean(tf.square(true_features - pred_features))


# --- Gradient Loss ---
def gradient_loss(y_true, y_pred):
    dy_true, dx_true = tf.image.image_gradients(y_true)
    dy_pred, dx_pred = tf.image.image_gradients(y_pred)
    return tf.reduce_mean(tf.abs(dy_true - dy_pred) + tf.abs(dx_true - dx_pred))


# --- Updated Combined Loss ---
def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

# Updated Combined Loss with SSIM
def combined_loss(y_true, y_pred):
    mse = tf.keras.losses.MeanSquaredError()(y_true, y_pred)
    dice = dice_loss(y_true, y_pred)
    perc = perceptual_loss(y_true, y_pred)
    grad = gradient_loss(y_true, y_pred)
    ssim = ssim_loss(y_true, y_pred)

# Adjusted weights for sharper transitions
    return 0.2 * mse + 0.15 * dice + 0.2 * perc + 0.2 * grad + 0.25 * ssim




# --- Dense UNet Model ---
def dense_unet(input_shape=(128, 128, 1)):
    def dense_block(x, filters, num_layers):
        for _ in range(num_layers):
            bn = BatchNormalization()(x)
            act = tf.keras.activations.relu(bn)
            conv = Conv2D(filters, (3, 3), padding="same")(act)
            x = Concatenate()([x, conv])  # Dense connection
        return x

    def transition_down(x, filters):
        x = Conv2D(filters, (1, 1), padding="same", activation="relu")(x)
        x = MaxPooling2D((2, 2))(x)
        return x

    def transition_up(x, filters):
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(filters, (3, 3), padding="same", activation="relu")(x)
        return x

    input_current = Input(shape=input_shape, name="current_input")
    input_pdn = Input(shape=input_shape, name="pdn_input")
    input_dist = Input(shape=input_shape, name="dist_input")
    merged_inputs = Concatenate()([input_current, input_pdn, input_dist])

    # Encoder
    d1 = dense_block(merged_inputs, 64, 4)
    t1 = transition_down(d1, 128)

    d2 = dense_block(t1, 128, 4)
    t2 = transition_down(d2, 256)

    d3 = dense_block(t2, 256, 4)
    t3 = transition_down(d3, 512)

    d4 = dense_block(t3, 512, 4)
    t4 = transition_down(d4, 1024)

    # Bottleneck
    bottleneck = dense_block(t4, 1024, 4)

    # Decoder
    u1 = transition_up(bottleneck, 512)
    u1 = Concatenate()([u1, d4])
    u1 = dense_block(u1, 512, 4)

    u2 = transition_up(u1, 256)
    u2 = Concatenate()([u2, d3])
    u2 = dense_block(u2, 256, 4)

    u3 = transition_up(u2, 128)
    u3 = Concatenate()([u3, d2])
    u3 = dense_block(u3, 128, 4)

    u4 = transition_up(u3, 64)
    u4 = Concatenate()([u4, d1])
    u4 = dense_block(u4, 64, 4)

    outputs = Conv2D(1, (1, 1), activation="sigmoid")(u4)
    model = Model(inputs=[input_current, input_pdn, input_dist], outputs=outputs)
    return model


# --- Compile and Train with Caching ---
model = dense_unet(input_shape=(128, 128, 1))
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss=combined_loss,
    metrics=["mae", "mse"],
)

# Cache and prefetch datasets
train_ds = tf.data.Dataset.from_tensor_slices(
    ((train_currents, train_pdns, train_dists), train_outputs)
)
train_ds = train_ds.cache().batch(8).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

test_ds = tf.data.Dataset.from_tensor_slices(
    ((test_currents, test_pdns, test_dists), test_outputs)
)
test_ds = test_ds.cache().batch(8).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

# Train the model
debug("Training the Dense UNet model...")
history = model.fit(train_ds, validation_data=test_ds, epochs=300)

# --- Visualization ---
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.title("Loss with Perceptual and Gradient Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Evaluate the model and visualize predictions
def visualize_predictions(test_currents, test_pdns, test_dists, test_outputs, model, num_samples=5):
    predictions = model.predict([test_currents, test_pdns, test_dists])

    for i in range(num_samples):
        # Calculate MSE and MAE
        mse = tf.keras.losses.MeanSquaredError()(test_outputs[i], predictions[i]).numpy()
        mae = tf.keras.losses.MeanAbsoluteError()(test_outputs[i], predictions[i]).numpy()

        # Plot all the inputs, ground truth, and prediction
        plt.figure(figsize=(15, 10))

        # Input Current
        plt.subplot(2, 3, 1)
        plt.imshow(test_currents[i, ..., 0], cmap="viridis")
        plt.title("Input Current")
        plt.axis("off")

        # Input PDN
        plt.subplot(2, 3, 2)
        plt.imshow(test_pdns[i, ..., 0], cmap="viridis")
        plt.title("Input PDN")
        plt.axis("off")

        # Input Effective Distance
        plt.subplot(2, 3, 3)
        plt.imshow(test_dists[i, ..., 0], cmap="viridis")
        plt.title("Input Effective Distance")
        plt.axis("off")

        # Ground Truth
        plt.subplot(2, 3, 4)
        plt.imshow(test_outputs[i, ..., 0], cmap="viridis")
        plt.title("Ground Truth")
        plt.axis("off")

        # Prediction with MSE and MAE
        plt.subplot(2, 3, 5)
        plt.imshow(predictions[i, ..., 0], cmap="viridis")
        plt.title(f"Prediction\nMSE: {mse:.4f}, MAE: {mae:.4f}")
        plt.axis("off")

        plt.tight_layout()
        plt.show()

# Visualize predictions for a few test samples
visualize_predictions(test_currents, test_pdns, test_dists, test_outputs, model, num_samples=10)


#################################################################################################################################################################################################################

import os
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import (
    Input,
    Conv2D,
    MaxPooling2D,
    UpSampling2D,
    Concatenate,
    BatchNormalization,
    Dropout,
    Add,
)
from tensorflow.keras.models import Model
from tensorflow.keras.applications import VGG19
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Debugging helper
def debug(message):
    print(f"[DEBUG] {message}")

# --- File Loading ---
def load_files(base_path):
    available_current_files = [
        os.path.join(base_path, file)
        for file in os.listdir(base_path)
        if "_current" in file and file.endswith(".csv") and "current_map" in file
    ]
    available_pdn_files = [
        os.path.join(base_path, file)
        for file in os.listdir(base_path)
        if "pdn_density" in file and file.endswith(".csv")
    ]
    available_dist_files = [
        os.path.join(base_path, file)
        for file in os.listdir(base_path)
        if "eff_dist" in file and file.endswith(".csv")
    ]
    available_ir_drop_files = [
        os.path.join(base_path, file)
        for file in os.listdir(base_path)
        if "ir_drop" in file and file.endswith(".csv") and "current_map" in file
    ]

    def extract_index(file_name):
        return int(file_name.split("map")[1].split("_")[0])

    available_current_files.sort(key=lambda f: extract_index(f))
    available_pdn_files.sort(key=lambda f: extract_index(f))
    available_dist_files.sort(key=lambda f: extract_index(f))
    available_ir_drop_files.sort(key=lambda f: extract_index(f))

    if not (
        len(available_current_files)
        == len(available_pdn_files)
        == len(available_dist_files)
        == len(available_ir_drop_files)
    ):
        raise ValueError(
            f"Mismatch in file counts: {len(available_current_files)} currents, {len(available_pdn_files)} PDNs, {len(available_dist_files)} distances, {len(available_ir_drop_files)} IR drops."
        )

    debug(
        f"Found {len(available_current_files)} current, {len(available_pdn_files)} PDN density, {len(available_dist_files)} effective distance, and {len(available_ir_drop_files)} IR drop files."
    )
    return available_current_files, available_pdn_files, available_dist_files, available_ir_drop_files

# --- Preprocessing ---
def preprocess_csv(file_path, target_shape=(256, 256)):
    debug(f"Processing file: {file_path}")
    data = pd.read_csv(file_path, header=None).to_numpy(dtype=np.float32)
    data = tf.image.resize(data[..., np.newaxis], target_shape, method="bilinear").numpy()
    max_val = np.max(data)
    return data / max_val if max_val > 0 else data

# --- Data Loading ---
def load_and_preprocess_data(base_path, target_shape=(256, 256)):
    current_files, pdn_files, dist_files, ir_drop_files = load_files(base_path)

    input_currents = np.array([preprocess_csv(file, target_shape) for file in current_files])
    input_pdns = np.array([preprocess_csv(file, target_shape) for file in pdn_files])
    input_dists = np.array([preprocess_csv(file, target_shape) for file in dist_files])
    output_images = np.array([preprocess_csv(file, target_shape) for file in ir_drop_files])

    return input_currents, input_pdns, input_dists, output_images

# --- Normalize Data ---
def normalize_data(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

# --- Usage Example ---
base_path = "/content/drive/My Drive/ML-for-IR-drop-main/benchmarks/fake-circuit-data/"
input_currents, input_pdns, input_dists, output_images = load_and_preprocess_data(base_path)

# --- Data Splitting ---
debug("Splitting data...")
split_idx = len(input_currents) - 10  # Train on all but the last 10
train_currents, test_currents = input_currents[:split_idx], input_currents[split_idx:]
train_pdns, test_pdns = input_pdns[:split_idx], input_pdns[split_idx:]
train_dists, test_dists = input_dists[:split_idx], input_dists[split_idx:]
train_outputs, test_outputs = output_images[:split_idx], output_images[split_idx:]

# Normalize training and validation sets
train_currents = normalize_data(train_currents)
test_currents = normalize_data(test_currents)
train_pdns = normalize_data(train_pdns)
test_pdns = normalize_data(test_pdns)
train_dists = normalize_data(train_dists)
test_dists = normalize_data(test_dists)
train_outputs = normalize_data(train_outputs)
test_outputs = normalize_data(test_outputs)

debug(f"Training size: {len(train_currents)}, Testing size: {len(test_currents)}")

# --- Loss Functions ---
def dice_loss(y_true, y_pred):
    numerator = 2 * tf.reduce_sum(y_true * y_pred)
    denominator = tf.reduce_sum(y_true + y_pred)
    return 1 - numerator / (denominator + tf.keras.backend.epsilon())

# Load VGG19 for perceptual loss
vgg = VGG19(weights="imagenet", include_top=False, input_shape=(256, 256, 3))
vgg.trainable = False
perceptual_layer = vgg.get_layer("block5_conv4").output
perceptual_model = Model(inputs=vgg.input, outputs=perceptual_layer)

def perceptual_loss(y_true, y_pred):
    y_true_rgb = tf.image.grayscale_to_rgb(y_true)
    y_pred_rgb = tf.image.grayscale_to_rgb(y_pred)
    true_features = perceptual_model(y_true_rgb)
    pred_features = perceptual_model(y_pred_rgb)
    return tf.reduce_mean(tf.square(true_features - pred_features))

def gradient_loss(y_true, y_pred):
    dy_true, dx_true = tf.image.image_gradients(y_true)
    dy_pred, dx_pred = tf.image.image_gradients(y_pred)
    return tf.reduce_mean(tf.abs(dy_true - dy_pred) + tf.abs(dx_true - dx_pred))

def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

def combined_loss(y_true, y_pred):
    mse = tf.keras.losses.MeanSquaredError()(y_true, y_pred)
    dice = dice_loss(y_true, y_pred)
    perc = perceptual_loss(y_true, y_pred)
    grad = gradient_loss(y_true, y_pred)
    ssim = ssim_loss(y_true, y_pred)
    return 0.4 * mse + 0.2 * perc + 0.15 * dice + 0.2 * grad + 0.05 * ssim

# --- Dense UNet Model ---
def dense_unet(input_shape=(256, 256, 1)):
    def dense_block(x, filters, num_layers):
        for _ in range(num_layers):
            bn = BatchNormalization()(x)
            act = tf.keras.activations.relu(bn)
            conv = Conv2D(filters, (3, 3), padding="same")(act)
            x = Concatenate()([x, conv])  # Dense connection
            x = Dropout(0.3)(x)  # Add dropout for regularization
        return x

    def transition_down(x, filters):
        x = Conv2D(filters, (1, 1), padding="same", activation="relu")(x)
        x = MaxPooling2D((2, 2))(x)
        return x

    def transition_up(x, filters):
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(filters, (3, 3), padding="same", activation="relu")(x)
        return x

    input_current = Input(shape=input_shape, name="current_input")
    input_pdn = Input(shape=input_shape, name="pdn_input")
    input_dist = Input(shape=input_shape, name="dist_input")
    merged_inputs = Concatenate()([input_current, input_pdn, input_dist])

    # Encoder
    d1 = dense_block(merged_inputs, 64, 4)
    t1 = transition_down(d1, 128)

    d2 = dense_block(t1, 128, 4)
    t2 = transition_down(d2, 256)

    d3 = dense_block(t2, 256, 4)
    t3 = transition_down(d3, 512)

    d4 = dense_block(t3, 512, 4)
    t4 = transition_down(d4, 1024)

    # Bottleneck
    bottleneck = dense_block(t4, 1024, 4)

    # Decoder with skip connections
    u1 = transition_up(bottleneck, 512)
    u1 = Concatenate()([u1, d4])
    u1 = dense_block(u1, 512, 4)

    u2 = transition_up(u1, 256)
    u2 = Concatenate()([u2, d3])
    u2 = dense_block(u2, 256, 4)

    u3 = transition_up(u2, 128)
    u3 = Concatenate()([u3, d2])
    u3 = dense_block(u3, 128, 4)

    u4 = transition_up(u3, 64)
    u4 = Concatenate()([u4, d1])
    u4 = dense_block(u4, 64, 4)

    outputs = Conv2D(1, (1, 1), activation="sigmoid")(u4)
    model = Model(inputs=[input_current, input_pdn, input_dist], outputs=outputs)
    return model

# --- Compile and Train with Early Stopping and Learning Rate Adjustment ---
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.0001,  # Reduced learning rate
    decay_steps=10000,
    decay_rate=0.96,
    staircase=True
)

reduce_lr = ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.5,
    patience=5,
    min_lr=1e-7,
    verbose=1
)

early_stopping = EarlyStopping(
    monitor="val_loss",
    patience=10,
    restore_best_weights=True
)

model = dense_unet(input_shape=(256, 256, 1))
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule, clipnorm=1.0),
    loss=combined_loss,
    metrics=["mae", "mse"]
)

train_ds = tf.data.Dataset.from_tensor_slices(
    ((train_currents, train_pdns, train_dists), train_outputs)
).batch(4).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

test_ds = tf.data.Dataset.from_tensor_slices(
    ((test_currents, test_pdns, test_dists), test_outputs)
).batch(4).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

history = model.fit(
    train_ds,
    validation_data=test_ds,
    epochs=300,
    callbacks=[early_stopping, reduce_lr]
)

# --- Visualization ---
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.title("Loss with Perceptual and Gradient Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

#################################################################################################################################################################################################################

import os
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import (
    Input,
    Conv2D,
    MaxPooling2D,
    UpSampling2D,
    Concatenate,
    BatchNormalization,
    Dropout,
    Add,
)
from tensorflow.keras.models import Model
from tensorflow.keras.applications import VGG19
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Debugging helper
def debug(message):
    print(f"[DEBUG] {message}")

# --- File Loading ---
def load_files(base_path):
    available_current_files = [
        os.path.join(base_path, file)
        for file in os.listdir(base_path)
        if "_current" in file and file.endswith(".csv") and "current_map" in file
    ]
    available_pdn_files = [
        os.path.join(base_path, file)
        for file in os.listdir(base_path)
        if "pdn_density" in file and file.endswith(".csv")
    ]
    available_dist_files = [
        os.path.join(base_path, file)
        for file in os.listdir(base_path)
        if "eff_dist" in file and file.endswith(".csv")
    ]
    available_ir_drop_files = [
        os.path.join(base_path, file)
        for file in os.listdir(base_path)
        if "ir_drop" in file and file.endswith(".csv") and "current_map" in file
    ]

    def extract_index(file_name):
        return int(file_name.split("map")[1].split("_")[0])

    available_current_files.sort(key=lambda f: extract_index(f))
    available_pdn_files.sort(key=lambda f: extract_index(f))
    available_dist_files.sort(key=lambda f: extract_index(f))
    available_ir_drop_files.sort(key=lambda f: extract_index(f))

    if not (
        len(available_current_files)
        == len(available_pdn_files)
        == len(available_dist_files)
        == len(available_ir_drop_files)
    ):
        raise ValueError(
            f"Mismatch in file counts: {len(available_current_files)} currents, {len(available_pdn_files)} PDNs, {len(available_dist_files)} distances, {len(available_ir_drop_files)} IR drops."
        )

    debug(
        f"Found {len(available_current_files)} current, {len(available_pdn_files)} PDN density, {len(available_dist_files)} effective distance, and {len(available_ir_drop_files)} IR drop files."
    )
    return available_current_files, available_pdn_files, available_dist_files, available_ir_drop_files

# --- Preprocessing ---
def preprocess_csv(file_path, target_shape=(192, 192)):
    debug(f"Processing file: {file_path}")
    data = pd.read_csv(file_path, header=None).to_numpy(dtype=np.float32)
    data = tf.image.resize(data[..., np.newaxis], target_shape, method="bilinear").numpy()
    max_val = np.max(data)
    return data / max_val if max_val > 0 else data

# --- Data Loading ---
def load_and_preprocess_data(base_path, target_shape=(192, 192)):
    current_files, pdn_files, dist_files, ir_drop_files = load_files(base_path)

    input_currents = np.array([preprocess_csv(file, target_shape) for file in current_files])
    input_pdns = np.array([preprocess_csv(file, target_shape) for file in pdn_files])
    input_dists = np.array([preprocess_csv(file, target_shape) for file in dist_files])
    output_images = np.array([preprocess_csv(file, target_shape) for file in ir_drop_files])

    return input_currents, input_pdns, input_dists, output_images

# --- Normalize Data ---
def normalize_data(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

# --- Usage Example ---
base_path = "/content/drive/My Drive/ML-for-IR-drop-main/benchmarks/fake-circuit-data/"
input_currents, input_pdns, input_dists, output_images = load_and_preprocess_data(base_path)

# --- Data Splitting ---
debug("Splitting data...")
split_idx = len(input_currents) - 10  # Train on all but the last 10
train_currents, test_currents = input_currents[:split_idx], input_currents[split_idx:]
train_pdns, test_pdns = input_pdns[:split_idx], input_pdns[split_idx:]
train_dists, test_dists = input_dists[:split_idx], input_dists[split_idx:]
train_outputs, test_outputs = output_images[:split_idx], output_images[split_idx:]

# Normalize training and validation sets
train_currents = normalize_data(train_currents)
test_currents = normalize_data(test_currents)
train_pdns = normalize_data(train_pdns)
test_pdns = normalize_data(test_pdns)
train_dists = normalize_data(train_dists)
test_dists = normalize_data(test_dists)
train_outputs = normalize_data(train_outputs)
test_outputs = normalize_data(test_outputs)

debug(f"Training size: {len(train_currents)}, Testing size: {len(test_currents)}")

# --- Loss Functions ---
def dice_loss(y_true, y_pred):
    numerator = 2 * tf.reduce_sum(y_true * y_pred)
    denominator = tf.reduce_sum(y_true + y_pred)
    return 1 - numerator / (denominator + tf.keras.backend.epsilon())

# Load VGG19 for perceptual loss
vgg = VGG19(weights="imagenet", include_top=False, input_shape=(192, 192, 3))
vgg.trainable = False
perceptual_layer = vgg.get_layer("block5_conv4").output
perceptual_model = Model(inputs=vgg.input, outputs=perceptual_layer)

def perceptual_loss(y_true, y_pred):
    y_true_rgb = tf.image.grayscale_to_rgb(y_true)
    y_pred_rgb = tf.image.grayscale_to_rgb(y_pred)
    true_features = perceptual_model(y_true_rgb)
    pred_features = perceptual_model(y_pred_rgb)
    return tf.reduce_mean(tf.square(true_features - pred_features))

def gradient_loss(y_true, y_pred):
    dy_true, dx_true = tf.image.image_gradients(y_true)
    dy_pred, dx_pred = tf.image.image_gradients(y_pred)
    return tf.reduce_mean(tf.abs(dy_true - dy_pred) + tf.abs(dx_true - dx_pred))

def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

def combined_loss(y_true, y_pred):
    mse = tf.keras.losses.MeanSquaredError()(y_true, y_pred)
    mae = tf.keras.losses.MeanAbsoluteError()(y_true, y_pred)
    dice = dice_loss(y_true, y_pred)
    perc = perceptual_loss(y_true, y_pred)
    grad = gradient_loss(y_true, y_pred)
    ssim = ssim_loss(y_true, y_pred)
    return 0.2 * mse + 0.15 * dice + 0.25 * ssim + 0.15 * grad + 0.2 * perc

# --- Dense UNet Model ---
def dense_unet(input_shape=(192, 192, 1)):
    def dense_block(x, filters, num_layers):
        for _ in range(num_layers):
            bn = BatchNormalization()(x)
            act = tf.keras.activations.relu(bn)
            conv = Conv2D(filters, (3, 3), padding="same")(act)
            x = Concatenate()([x, conv])  # Dense connection
            x = Dropout(0.3)(x)  # Add dropout for regularization
        return x

    def transition_down(x, filters):
        x = Conv2D(filters, (1, 1), padding="same", activation="relu")(x)
        x = MaxPooling2D((2, 2))(x)
        return x

    def transition_up(x, filters):
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(filters, (3, 3), padding="same", activation="relu")(x)
        return x

    input_current = Input(shape=input_shape, name="current_input")
    input_pdn = Input(shape=input_shape, name="pdn_input")
    input_dist = Input(shape=input_shape, name="dist_input")
    merged_inputs = Concatenate()([input_current, input_pdn, input_dist])

    # Encoder
    d1 = dense_block(merged_inputs, 64, 4)
    t1 = transition_down(d1, 128)

    d2 = dense_block(t1, 128, 4)
    t2 = transition_down(d2, 256)

    d3 = dense_block(t2, 256, 4)
    t3 = transition_down(d3, 512)

    d4 = dense_block(t3, 512, 4)
    t4 = transition_down(d4, 1024)

    # Bottleneck
    bottleneck = dense_block(t4, 1024, 4)

    # Decoder with skip connections
    u1 = transition_up(bottleneck, 512)
    u1 = Concatenate()([u1, d4])
    u1 = dense_block(u1, 512, 4)

    u2 = transition_up(u1, 256)
    u2 = Concatenate()([u2, d3])
    u2 = dense_block(u2, 256, 4)

    u3 = transition_up(u2, 128)
    u3 = Concatenate()([u3, d2])
    u3 = dense_block(u3, 128, 4)

    u4 = transition_up(u3, 64)
    u4 = Concatenate()([u4, d1])
    u4 = dense_block(u4, 64, 4)

    outputs = Conv2D(1, (1, 1), activation="sigmoid")(u4)
    model = Model(inputs=[input_current, input_pdn, input_dist], outputs=outputs)
    return model

# Define the learning rate schedule
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.0001,  # Starting learning rate
    decay_steps=10000,
    decay_rate=0.96,
    staircase=True
)

early_stopping = EarlyStopping(
    monitor="val_loss",
    patience=10,
    restore_best_weights=True
)

model = dense_unet(input_shape=(192, 192, 1))
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1.0),
    loss=combined_loss,
    metrics=["mae", "mse"]
)

train_ds = tf.data.Dataset.from_tensor_slices(
    ((train_currents, train_pdns, train_dists), train_outputs)
).batch(8).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

test_ds = tf.data.Dataset.from_tensor_slices(
    ((test_currents, test_pdns, test_dists), test_outputs)
).batch(8).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

history = model.fit(
    train_ds,
    validation_data=test_ds,
    epochs=100,
)

# --- Visualization ---
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.title("Loss with Perceptual and Gradient Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Evaluate the model and visualize predictions
def visualize_predictions(test_currents, test_pdns, test_dists, test_outputs, model, num_samples=5):
    predictions = model.predict([test_currents, test_pdns, test_dists])

    for i in range(num_samples):
        # Calculate MSE and MAE
        mse = tf.keras.losses.MeanSquaredError()(test_outputs[i], predictions[i]).numpy()
        mae = tf.keras.losses.MeanAbsoluteError()(test_outputs[i], predictions[i]).numpy()

        # Plot all the inputs, ground truth, and prediction
        plt.figure(figsize=(12, 5))

        # Input Current
        plt.subplot(2, 3, 1)
        plt.imshow(test_currents[i, ..., 0], cmap="viridis")
        plt.title("Input Current")
        plt.axis("off")

        # Input PDN
        plt.subplot(2, 3, 2)
        plt.imshow(test_pdns[i, ..., 0], cmap="viridis")
        plt.title("Input PDN")
        plt.axis("off")

        # Input Effective Distance
        plt.subplot(2, 3, 3)
        plt.imshow(test_dists[i, ..., 0], cmap="viridis")
        plt.title("Input Effective Distance")
        plt.axis("off")

        # Ground Truth
        plt.subplot(2, 3, 4)
        plt.imshow(test_outputs[i, ..., 0], cmap="viridis")
        plt.title("Ground Truth")
        plt.axis("off")

        # Prediction with MSE and MAE
        plt.subplot(2, 3, 5)
        plt.imshow(predictions[i, ..., 0], cmap="viridis")
        plt.title(f"Prediction\nMSE: {mse:.4f}, MAE: {mae:.4f}")
        plt.axis("off")

        plt.tight_layout()
        plt.show()

# Visualize predictions for a few test samples
visualize_predictions(test_currents, test_pdns, test_dists, test_outputs, model, num_samples=10)

#################################################################################################################################################################################################################

import os
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import (
    Input,
    Conv2D,
    MaxPooling2D,
    UpSampling2D,
    Concatenate,
    BatchNormalization,
    Dropout,
    Add,
)
from tensorflow.keras.models import Model
from tensorflow.keras.applications import VGG19


# Debugging helper
def debug(message):
    print(f"[DEBUG] {message}")


# --- Preprocessing ---
base_path = "/content/drive/My Drive/ML-for-IR-drop-main/benchmarks/fake-circuit-data/"

# Dynamically find files
available_current_files = [
    os.path.join(base_path, file)
    for file in os.listdir(base_path)
    if "_current" in file and file.endswith(".csv") and "current_map" in file
]
available_pdn_files = [
    os.path.join(base_path, file)
    for file in os.listdir(base_path)
    if "pdn_density" in file and file.endswith(".csv")
]
available_dist_files = [
    os.path.join(base_path, file)
    for file in os.listdir(base_path)
    if "eff_dist" in file and file.endswith(".csv")
]
available_ir_drop_files = [
    os.path.join(base_path, file)
    for file in os.listdir(base_path)
    if "ir_drop" in file and file.endswith(".csv") and "current_map" in file
]


# Sort by numeric indices
def extract_index(file_name):
    return int(file_name.split("map")[1].split("_")[0])


available_current_files.sort(key=lambda f: extract_index(f))
available_pdn_files.sort(key=lambda f: extract_index(f))
available_dist_files.sort(key=lambda f: extract_index(f))
available_ir_drop_files.sort(key=lambda f: extract_index(f))

# Ensure alignment of files
if not (
    len(available_current_files)
    == len(available_pdn_files)
    == len(available_dist_files)
    == len(available_ir_drop_files)
):
    raise ValueError(
        f"Mismatch in file counts: {len(available_current_files)} currents, {len(available_pdn_files)} PDNs, {len(available_dist_files)} distances, {len(available_ir_drop_files)} IR drops."
    )

debug(
    f"Found {len(available_current_files)} current, {len(available_pdn_files)} PDN density, {len(available_dist_files)} effective distance, and {len(available_ir_drop_files)} IR drop files."
)


# Preprocess CSV files
def preprocess_csv(file_path, target_shape=(128, 128)):
    debug(f"Processing file: {file_path}")
    data = pd.read_csv(file_path, header=None).to_numpy(dtype=np.float32)
    data = tf.image.resize(data[..., np.newaxis], target_shape, method="bilinear").numpy()
    max_val = np.max(data)
    return data / max_val if max_val > 0 else data


# Load and preprocess data
input_currents = np.array([preprocess_csv(file) for file in available_current_files])
input_pdns = np.array([preprocess_csv(file) for file in available_pdn_files])
input_dists = np.array([preprocess_csv(file) for file in available_dist_files])
output_images = np.array([preprocess_csv(file) for file in available_ir_drop_files])

# --- Data Splitting ---
debug("Splitting data...")
split_idx = len(input_currents) - 10  # Train on all but the last 10
train_currents, test_currents = input_currents[:split_idx], input_currents[split_idx:]
train_pdns, test_pdns = input_pdns[:split_idx], input_pdns[split_idx:]
train_dists, test_dists = input_dists[:split_idx], input_dists[split_idx:]
train_outputs, test_outputs = output_images[:split_idx], output_images[split_idx:]

debug(f"Training size: {len(train_currents)}, Testing size: {len(test_currents)}")

# --- Loss Functions ---
def dice_loss(y_true, y_pred):
    numerator = 2 * tf.reduce_sum(y_true * y_pred)
    denominator = tf.reduce_sum(y_true + y_pred)
    return 1 - numerator / (denominator + tf.keras.backend.epsilon())


def mape_loss(y_true, y_pred):
    return tf.reduce_mean(
        tf.abs((y_true - y_pred) / tf.clip_by_value(y_true, 1e-7, tf.reduce_max(y_true)))
    )


# Load VGG19 for perceptual loss
vgg = VGG19(weights="imagenet", include_top=False, input_shape=(128, 128, 3))
vgg.trainable = False
perceptual_layer = vgg.get_layer("block5_conv4").output
perceptual_model = Model(inputs=vgg.input, outputs=perceptual_layer)


def perceptual_loss(y_true, y_pred):
    y_true_rgb = tf.image.grayscale_to_rgb(y_true)
    y_pred_rgb = tf.image.grayscale_to_rgb(y_pred)
    true_features = perceptual_model(y_true_rgb)
    pred_features = perceptual_model(y_pred_rgb)
    return tf.reduce_mean(tf.square(true_features - pred_features))


# --- Gradient Loss ---
def gradient_loss(y_true, y_pred):
    dy_true, dx_true = tf.image.image_gradients(y_true)
    dy_pred, dx_pred = tf.image.image_gradients(y_pred)
    return tf.reduce_mean(tf.abs(dy_true - dy_pred) + tf.abs(dx_true - dx_pred))


# --- Updated Combined Loss ---
def ssim_loss(y_true, y_pred):
    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))

# Updated Combined Loss with SSIM
def combined_loss(y_true, y_pred):
    mse = tf.keras.losses.MeanSquaredError()(y_true, y_pred)
    dice = dice_loss(y_true, y_pred)
    perc = perceptual_loss(y_true, y_pred)
    grad = gradient_loss(y_true, y_pred)
    ssim = ssim_loss(y_true, y_pred)

# Adjusted weights for sharper transitions
    return 0.2 * mse + 0.15 * dice + 0.2 * perc + 0.2 * grad + 0.25 * ssim




# --- Dense UNet Model ---
def dense_unet(input_shape=(128, 128, 1)):
    def dense_block(x, filters, num_layers):
        for _ in range(num_layers):
            bn = BatchNormalization()(x)
            act = tf.keras.activations.relu(bn)
            conv = Conv2D(filters, (3, 3), padding="same")(act)
            x = Concatenate()([x, conv])  # Dense connection
        return x

    def transition_down(x, filters):
        x = Conv2D(filters, (1, 1), padding="same", activation="relu")(x)
        x = MaxPooling2D((2, 2))(x)
        return x

    def transition_up(x, filters):
        x = UpSampling2D((2, 2))(x)
        x = Conv2D(filters, (3, 3), padding="same", activation="relu")(x)
        return x

    input_current = Input(shape=input_shape, name="current_input")
    input_pdn = Input(shape=input_shape, name="pdn_input")
    input_dist = Input(shape=input_shape, name="dist_input")
    merged_inputs = Concatenate()([input_current, input_pdn, input_dist])

    # Encoder
    d1 = dense_block(merged_inputs, 64, 4)
    t1 = transition_down(d1, 128)

    d2 = dense_block(t1, 128, 4)
    t2 = transition_down(d2, 256)

    d3 = dense_block(t2, 256, 4)
    t3 = transition_down(d3, 512)

    d4 = dense_block(t3, 512, 4)
    t4 = transition_down(d4, 1024)

    # Bottleneck
    bottleneck = dense_block(t4, 1024, 4)

    # Decoder
    u1 = transition_up(bottleneck, 512)
    u1 = Concatenate()([u1, d4])
    u1 = dense_block(u1, 512, 4)

    u2 = transition_up(u1, 256)
    u2 = Concatenate()([u2, d3])
    u2 = dense_block(u2, 256, 4)

    u3 = transition_up(u2, 128)
    u3 = Concatenate()([u3, d2])
    u3 = dense_block(u3, 128, 4)

    u4 = transition_up(u3, 64)
    u4 = Concatenate()([u4, d1])
    u4 = dense_block(u4, 64, 4)

    outputs = Conv2D(1, (1, 1), activation="sigmoid")(u4)
    model = Model(inputs=[input_current, input_pdn, input_dist], outputs=outputs)
    return model


# --- Compile and Train with Caching ---
model = dense_unet(input_shape=(128, 128, 1))
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss=combined_loss,
    metrics=["mae", "mse"],
)

# Cache and prefetch datasets
train_ds = tf.data.Dataset.from_tensor_slices(
    ((train_currents, train_pdns, train_dists), train_outputs)
)
train_ds = train_ds.cache().batch(8).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

test_ds = tf.data.Dataset.from_tensor_slices(
    ((test_currents, test_pdns, test_dists), test_outputs)
)
test_ds = test_ds.cache().batch(8).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

# Train the model
debug("Training the Dense UNet model...")
history = model.fit(train_ds, validation_data=test_ds, epochs=500)

# --- Visualization ---
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.title("Loss with Perceptual and Gradient Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Evaluate the model and visualize predictions
def visualize_predictions(test_currents, test_pdns, test_dists, test_outputs, model, num_samples=5):
    predictions = model.predict([test_currents, test_pdns, test_dists])

    for i in range(num_samples):
        # Calculate MSE and MAE
        mse = tf.keras.losses.MeanSquaredError()(test_outputs[i], predictions[i]).numpy()
        mae = tf.keras.losses.MeanAbsoluteError()(test_outputs[i], predictions[i]).numpy()

        # Plot all the inputs, ground truth, and prediction
        plt.figure(figsize=(12, 5))

        # Input Current
        plt.subplot(2, 3, 1)
        plt.imshow(test_currents[i, ..., 0], cmap="viridis")
        plt.title("Input Current")
        plt.axis("off")

        # Input PDN
        plt.subplot(2, 3, 2)
        plt.imshow(test_pdns[i, ..., 0], cmap="viridis")
        plt.title("Input PDN")
        plt.axis("off")

        # Input Effective Distance
        plt.subplot(2, 3, 3)
        plt.imshow(test_dists[i, ..., 0], cmap="viridis")
        plt.title("Input Effective Distance")
        plt.axis("off")

        # Ground Truth
        plt.subplot(2, 3, 4)
        plt.imshow(test_outputs[i, ..., 0], cmap="viridis")
        plt.title("Ground Truth")
        plt.axis("off")

        # Prediction with MSE and MAE
        plt.subplot(2, 3, 5)
        plt.imshow(predictions[i, ..., 0], cmap="viridis")
        plt.title(f"Prediction\nMSE: {mse:.4f}, MAE: {mae:.4f}")
        plt.axis("off")

        plt.tight_layout()
        plt.show()

# Visualize predictions for a few test samples
visualize_predictions(test_currents, test_pdns, test_dists, test_outputs, model, num_samples=10)

